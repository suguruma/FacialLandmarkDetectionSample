{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/elix-tech/kaggle-facial-keypoints/blob/master/kfkd.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Terada\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from collections import OrderedDict\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download from https://www.kaggle.com/c/facial-keypoints-detection/data\n",
    "FTRAIN = 'data/training.csv'\n",
    "FTEST = 'data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SPECIALIST_SETTINGS = [\n",
    "    dict(\n",
    "        columns=(\n",
    "            'left_eye_center_x', 'left_eye_center_y',\n",
    "            'right_eye_center_x', 'right_eye_center_y',\n",
    "            ),\n",
    "        flip_indices=((0, 2), (1, 3)),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'nose_tip_x', 'nose_tip_y',\n",
    "            ),\n",
    "        flip_indices=(),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'mouth_left_corner_x', 'mouth_left_corner_y',\n",
    "            'mouth_right_corner_x', 'mouth_right_corner_y',\n",
    "            'mouth_center_top_lip_x', 'mouth_center_top_lip_y',\n",
    "            ),\n",
    "        flip_indices=((0, 2), (1, 3)),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'mouth_center_bottom_lip_x',\n",
    "            'mouth_center_bottom_lip_y',\n",
    "            ),\n",
    "        flip_indices=(),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'left_eye_inner_corner_x', 'left_eye_inner_corner_y',\n",
    "            'right_eye_inner_corner_x', 'right_eye_inner_corner_y',\n",
    "            'left_eye_outer_corner_x', 'left_eye_outer_corner_y',\n",
    "            'right_eye_outer_corner_x', 'right_eye_outer_corner_y',\n",
    "            ),\n",
    "        flip_indices=((0, 2), (1, 3), (4, 6), (5, 7)),\n",
    "        ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'left_eyebrow_inner_end_x', 'left_eyebrow_inner_end_y',\n",
    "            'right_eyebrow_inner_end_x', 'right_eyebrow_inner_end_y',\n",
    "            'left_eyebrow_outer_end_x', 'left_eyebrow_outer_end_y',\n",
    "            'right_eyebrow_outer_end_x', 'right_eyebrow_outer_end_y',\n",
    "            ),\n",
    "        flip_indices=((0, 2), (1, 3), (4, 6), (5, 7)),\n",
    "        ),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load(test=False, cols=None):\n",
    "\n",
    "    fname = FTEST if test else FTRAIN\n",
    "    df = read_csv(os.path.expanduser(fname))\n",
    "\n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "\n",
    "    if cols:\n",
    "        df = df[list(cols) + ['Image']]\n",
    "\n",
    "    print(df.count())\n",
    "    df = df.dropna()\n",
    "\n",
    "    X = np.vstack(df['Image'].values) / 255.\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    if not test:\n",
    "        y = df[df.columns[:-1]].values\n",
    "        y = (y - 48) / 48\n",
    "        X, y = shuffle(X, y, random_state=42)\n",
    "        y = y.astype(np.float32)\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load2d(test=False, cols=None):\n",
    "    X, y = load(test, cols)\n",
    "    X = X.reshape(-1, 96, 96, 1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_sample(x, y, axis):\n",
    "    img = x.reshape(96, 96)\n",
    "    axis.imshow(img, cmap='gray')\n",
    "    axis.scatter(y[0::2]*48+48, y[1::2]*48+48, marker='x', s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FlippedImageDataGenerator(ImageDataGenerator):\n",
    "    flip_indices = [\n",
    "        (0, 2), (1, 3),\n",
    "        (4, 8), (5, 9), (6, 10), (7, 11),\n",
    "        (12, 16), (13, 17), (14, 18), (15, 19),\n",
    "        (22, 24), (23, 25),\n",
    "        ]\n",
    "\n",
    "    def next(self):\n",
    "        X_batch, y_batch = super(FlippedImageDataGenerator, self).next()\n",
    "        batch_size = X_batch.shape[0]\n",
    "        indices = np.random.choice(batch_size, batch_size/2, replace=False)\n",
    "        X_batch[indices] = X_batch[indices, :, :, ::-1]\n",
    "\n",
    "        if y_batch is not None:\n",
    "            y_batch[indices, ::2] = y_batch[indices, ::2] * -1\n",
    "\n",
    "            for a, b in self.flip_indices:\n",
    "                y_batch[indices, a], y_batch[indices, b] = (\n",
    "                    y_batch[indices, b], y_batch[indices, a]\n",
    "                )\n",
    "\n",
    "        return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Terada\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(96, 96, 1...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Terada\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (2, 2))`\n",
      "  \n",
      "C:\\Users\\Terada\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (2, 2))`\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(96, 96, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Convolution2D(64, 2, 2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Convolution2D(128, 2, 2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_specialists(fname_pretrain=None):\n",
    "    specialists = OrderedDict()\n",
    "    start = 0.03\n",
    "    stop = 0.001\n",
    "    nb_epoch = 10000\n",
    "\n",
    "    for setting in SPECIALIST_SETTINGS:\n",
    "\n",
    "        cols = setting['columns']\n",
    "        X, y = load2d(cols=cols)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        model_specialist = model_from_json(model.to_json())\n",
    "\n",
    "        if fname_pretrain:\n",
    "            model_specialist.load_weights(fname_pretrain)\n",
    "\n",
    "        model_specialist.layers.pop()\n",
    "        model_specialist.outputs = [model_specialist.layers[-1].output]\n",
    "        model_specialist.layers[-1].outbound_nodes = []\n",
    "        model_specialist.add(Dense(len(cols)))\n",
    "\n",
    "        sgd = SGD(lr=start, momentum=0.9, nesterov=True)\n",
    "        model_specialist.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "\n",
    "        # from keras.utils.visualize_util import plot\n",
    "        # plot(model_specialist, to_file=\"model8_{}.png\".format(cols[0]), show_shapes=True)\n",
    "\n",
    "        flipgen = FlippedImageDataGenerator()\n",
    "        flipgen.flip_indices = setting['flip_indices']\n",
    "\n",
    "        early_stop = EarlyStopping(patience=100)\n",
    "        learning_rates = np.linspace(start, stop, nb_epoch)\n",
    "        change_lr = LearningRateScheduler(lambda epoch: float(learning_rates[epoch]))\n",
    "\n",
    "        print(\"Training model for columns {} for {} epochs\".format(cols, nb_epoch))\n",
    "\n",
    "        hist = model_specialist.fit_generator(flipgen.flow(X_train, y_train),\n",
    "                                     samples_per_epoch=X_train.shape[0],\n",
    "                                     nb_epoch=nb_epoch,\n",
    "                                     validation_data=(X_val, y_val),\n",
    "                                     callbacks=[change_lr, early_stop])\n",
    "\n",
    "        specialists[cols] = model_specialist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_eye_center_x     7039\n",
      "left_eye_center_y     7039\n",
      "right_eye_center_x    7036\n",
      "right_eye_center_y    7036\n",
      "Image                 7049\n",
      "dtype: int64\n",
      "Training model for columns ('left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x', 'right_eye_center_y') for 10000 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Terada\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\Terada\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=175, epochs=10000)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    }
   ],
   "source": [
    "fit_specialists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
